{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCWkTgzfinJVGZdLYV4VQX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshrayella/NLP/blob/main/Lab8_4_dinesh_2403a54099.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "z0nxUz7tzAme"
      },
      "outputs": [],
      "source": [
        "#Corpus\n",
        "D1 = \"Artificial intelligence is transforming industries\"\n",
        "D2 = \"Machine learning models learn from data\"\n",
        "D3 = \"Deep learning is a subset of machine learning\"\n",
        "D4 = \"Data science involves statistics and programming\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Uni Gram Counts\n",
        "import collections\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "V = len(unigram_counts)\n",
        "print(\"Vocabulary Size=\", V)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TV2FVjqF-IvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c61467-24ac-43a2-e0eb-2e58920a966f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "learning: 3\n",
            "is: 2\n",
            "machine: 2\n",
            "data: 2\n",
            "artificial: 1\n",
            "intelligence: 1\n",
            "transforming: 1\n",
            "industries: 1\n",
            "models: 1\n",
            "learn: 1\n",
            "from: 1\n",
            "deep: 1\n",
            "a: 1\n",
            "subset: 1\n",
            "of: 1\n",
            "science: 1\n",
            "involves: 1\n",
            "statistics: 1\n",
            "and: 1\n",
            "programming: 1\n",
            "Vocabulary Size= 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Bi-Gram Counts\n",
        "import collections\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WJUit423-oJ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49f4566-3888-44ae-9365-1423439429fd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "machine learning: 2\n",
            "artificial intelligence: 1\n",
            "intelligence is: 1\n",
            "is transforming: 1\n",
            "transforming industries: 1\n",
            "industries machine: 1\n",
            "learning models: 1\n",
            "models learn: 1\n",
            "learn from: 1\n",
            "from data: 1\n",
            "data deep: 1\n",
            "deep learning: 1\n",
            "learning is: 1\n",
            "is a: 1\n",
            "a subset: 1\n",
            "subset of: 1\n",
            "of machine: 1\n",
            "learning data: 1\n",
            "data science: 1\n",
            "science involves: 1\n",
            "involves statistics: 1\n",
            "statistics and: 1\n",
            "and programming: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next Word Prediction Using Bi-Gram Counts\n",
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UcRMG_C2Ae7N",
        "outputId": "6b2e4981-8175-4479-e14a-27ae63b72414"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "Given sequence: 'professor I', predicted next word: 'No bigram found starting with 'i'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment of Bi-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sqoVvW7bAn00",
        "outputId": "d32f5a1c-d75c-446a-d7b8-2c6131316da8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textData science\n",
            "probability of  involves is  1.0\n",
            "Given sequence: 'Data science', predicted next word: 'involves'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening\n",
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count + 1) / (last_word_unigram_count + V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeJxmhiGCAKf",
        "outputId": "3d538a87-35ee-4546-c7bb-2ce1961fe9c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "Given sequence: 'professor I', predicted next word: 'No bigram found starting with 'i'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment of Laplace Smoothening based Bi-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "apjFfM-ECbpG",
        "outputId": "766ffa7b-bcb2-425e-be21-3d7bb0705647"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textinvolves statistics\n",
            "probability of and is  0.09523809523809523\n",
            "Given sequence: 'involves statistics', predicted next word: 'and'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next Word Prediction Using Bi-Gram Counts with Add-K Smoothening\n",
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count + K) / (last_word_unigram_count + K * V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"professor I\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "93ChJIZQD_Km",
        "outputId": "122a3af2-94f8-4b4b-ea3a-daad3fff43e0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No bigram found starting with 'my'.'\n",
            "Given sequence: 'professor I', predicted next word: 'No bigram found starting with 'i'.'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment of Add-K Smoothening based Bi-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9x8Gyj2eEcTk",
        "outputId": "830e55c8-8e21-4c71-b4ae-52a145638383"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textsubset of\n",
            "probability of machine is  0.13636363636363635\n",
            "Given sequence: 'subset of', predicted next word: 'machine'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tri-Gram Counts\n",
        "import collections\n",
        "\n",
        "combined_text = f\"{D1} {D2} {D3} {D4}\"\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2_4M0On6BBZX",
        "outputId": "03e57142-b56f-43a3-fbe4-cff00d447bfb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "artificial intelligence is: 1\n",
            "intelligence is transforming: 1\n",
            "is transforming industries: 1\n",
            "transforming industries machine: 1\n",
            "industries machine learning: 1\n",
            "machine learning models: 1\n",
            "learning models learn: 1\n",
            "models learn from: 1\n",
            "learn from data: 1\n",
            "from data deep: 1\n",
            "data deep learning: 1\n",
            "deep learning is: 1\n",
            "learning is a: 1\n",
            "is a subset: 1\n",
            "a subset of: 1\n",
            "subset of machine: 1\n",
            "of machine learning: 1\n",
            "machine learning data: 1\n",
            "learning data science: 1\n",
            "data science involves: 1\n",
            "science involves statistics: 1\n",
            "involves statistics and: 1\n",
            "statistics and programming: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next Word Prediction Using Tri-Gram Counts\n",
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iClfqBbBBO1N",
        "outputId": "01e9a00e-08f1-4050-e161-bba8cbd57c63"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment of Tri-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Aov8x4kaBjjM",
        "outputId": "0fe48bb1-5c2a-48db-faa6-64d71aec3c03"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textMachine learning models\n",
            "probability of  learn is  1.0\n",
            "Given sequence: 'Machine learning models', predicted next word: 'learn'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next Word Prediction Using Tri-Gram Counts based on laplace smoothening\n",
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count + 1) / (last_two_words_bigram_count + V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AHOjIPhACjhe",
        "outputId": "16a82ae1-abef-4575-ecd4-9d66c3003afc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Deployment of Laplace Smoothening based Tri-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qRb-yQbCC6Sd",
        "outputId": "acb9e317-2d49-4205-f276-61b63e1f85f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textArtificial intelligence is \n",
            "probability of  transforming is  0.09523809523809523\n",
            "Given sequence: 'Artificial intelligence is ', predicted next word: 'transforming'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#next Word Prediction Using Tri-Gram Counts with Add - K Smoothening\n",
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts, K):\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count + K) / (last_two_words_bigram_count + K * V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "sequence1 = \"I am working\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts, 0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vADS6_AxE3Xt",
        "outputId": "43b03dc7-00f6-47e5-e2a6-bf2beb174dbd"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am working', predicted next word: 'No trigram found starting with 'am working'.'\n",
            "Given sequence: 'I did my', predicted next word: 'No trigram found starting with 'did my'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Deployment of Add-K Smoothening based Tri-Gram Model\n",
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "id": "wbyLch7XFf61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bbf954c-608c-40de-9f01-eea881d6d8e0"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textinvolves statistics and\n",
            "probability of  programming is  0.13636363636363635\n",
            "Given sequence: 'involves statistics and', predicted next word: 'programming'\n"
          ]
        }
      ]
    }
  ]
}